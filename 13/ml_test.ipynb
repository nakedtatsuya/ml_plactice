{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0993ef30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 20:12:39.879918: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-15 20:12:39.879968: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b73e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test,\n",
    "                               y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e403c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3954b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 20:12:43.332775: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-15 20:12:43.332909: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-15 20:12:43.332932: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-GC2VT9N): /proc/driver/nvidia/version does not exist\n",
      "2022-05-15 20:12:43.333270: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb55dee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_example(image, label):\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    return tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "          feature={\n",
    "            \"image\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_data.numpy()])),\n",
    "            \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "          }\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "953f9898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"image\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\004\\022\\010\\022\\002\\010\\034\\022\\002\\010\\034\\\"\\220\\006\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\rI\\000\\000\\001\\004\\000\\000\\000\\000\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000$\\210\\177>6\\000\\000\\000\\001\\003\\004\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000f\\314\\260\\206\\220{\\027\\000\\000\\000\\000\\014\\n\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\233\\354\\317\\262k\\234\\241m@\\027M\\202H\\017\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000E\\317\\337\\332\\330\\330\\243\\177yz\\222\\215X\\254B\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\001\\001\\000\\310\\350\\350\\351\\345\\337\\337\\327\\325\\244\\177{\\304\\345\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\267\\341\\330\\337\\344\\353\\343\\340\\336\\340\\335\\337\\365\\255\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\301\\344\\332\\325\\306\\264\\324\\322\\323\\325\\337\\334\\363\\312\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\003\\000\\014\\333\\334\\324\\332\\300\\251\\343\\320\\332\\340\\324\\342\\305\\3214\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000c\\364\\336\\334\\332\\313\\306\\335\\327\\325\\336\\334\\365w\\2478\\000\\000\\000\\000\\000\\000\\000\\000\\000\\004\\000\\0007\\354\\344\\346\\344\\360\\350\\325\\332\\337\\352\\331\\331\\321\\\\\\000\\000\\000\\001\\004\\006\\007\\002\\000\\000\\000\\000\\000\\355\\342\\331\\337\\336\\333\\336\\335\\330\\337\\345\\327\\332\\377M\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000>\\221\\314\\344\\317\\325\\335\\332\\320\\323\\332\\340\\337\\333\\327\\340\\364\\237\\000\\000\\000\\000\\000\\022,Rk\\275\\344\\334\\336\\331\\342\\310\\315\\323\\346\\340\\352\\260\\274\\372\\370\\351\\356\\327\\000\\0009\\273\\320\\340\\335\\340\\320\\314\\326\\320\\321\\310\\237\\365\\301\\316\\337\\377\\377\\335\\352\\335\\323\\334\\350\\366\\000\\003\\312\\344\\340\\335\\323\\323\\326\\315\\315\\315\\334\\360P\\226\\377\\345\\335\\274\\232\\277\\322\\314\\321\\336\\344\\341\\000b\\351\\306\\322\\336\\345\\345\\352\\371\\334\\302\\327\\331\\361AIju\\250\\333\\335\\327\\331\\337\\337\\340\\345\\035K\\314\\324\\314\\301\\315\\323\\341\\330\\271\\305\\316\\306\\325\\360\\303\\343\\365\\357\\337\\332\\324\\321\\336\\334\\335\\346C0\\313\\267\\302\\325\\305\\271\\276\\302\\300\\312\\326\\333\\335\\334\\354\\341\\330\\307\\316\\272\\265\\261\\254\\265\\315\\316s\\000z\\333\\301\\263\\253\\267\\304\\314\\322\\325\\317\\323\\322\\310\\304\\302\\277\\303\\277\\306\\300\\260\\234\\247\\261\\322\\\\\\000\\000J\\275\\324\\277\\257\\254\\257\\265\\271\\274\\275\\274\\301\\306\\314\\321\\322\\322\\323\\274\\274\\302\\300\\330\\252\\000\\002\\000\\000\\000B\\310\\336\\355\\357\\362\\366\\363\\364\\335\\334\\301\\277\\263\\266\\266\\265\\260\\246\\250c:\\000\\000\\000\\000\\000\\000\\000\\000\\000(=,H)#\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image, label in valid_set.take(1):\n",
    "    print(create_example(image, label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00dc4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "\n",
    "def write_tfrecords(name, dataset, n_shards=10):\n",
    "    paths = [\"{}.tfrecord-{:05d}-of-{:05d}\".format(name, index, n_shards)\n",
    "             for index in range(n_shards)]\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path))\n",
    "                   for path in paths]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0badf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = write_tfrecords(\"my_fashion_mnist.train\", train_set)\n",
    "valid_filepaths = write_tfrecords(\"my_fashion_mnist.valid\", valid_set)\n",
    "test_filepaths = write_tfrecords(\"my_fashion_mnist.test\", test_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386743e6",
   "metadata": {},
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3746e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    #image = tf.io.decode_jpeg(example[\"image\"])\n",
    "    image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example[\"label\"]\n",
    "\n",
    "\n",
    "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,\n",
    "                  n_parse_threads=5, batch_size=32, cache=True):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths,\n",
    "                                      num_parallel_reads=n_read_threads)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd702281",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
    "valid_set = mnist_dataset(valid_filepaths)\n",
    "test_set = mnist_dataset(test_filepaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d826870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "098b3d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.layers.Normalization(\n",
    "#     axis=-1, mean=None, variance=None, invert=False, **kwargs\n",
    "# )\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# class Standardization(keras.layers.Layer):\n",
    "#     def adapt(self, data_sample):\n",
    "#         self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "#         self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())\n",
    "\n",
    "\n",
    "# standardization = Standardization(input_shape=[28, 28])\n",
    "standardization = keras.layers.Normalization(input_shape=[28, 28])\n",
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
    "                               axis=0).astype(np.float32)\n",
    "\n",
    "standardization.adapt(sample_images)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    standardization,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e7ef69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 20:16:27.883800: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-05-15 20:16:27.883883: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-05-15 20:16:27.884809: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     41/Unknown - 1s 6ms/step - loss: 1.0508 - accuracy: 0.6288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 20:16:28.633918: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-05-15 20:16:28.633991: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-05-15 20:16:28.641000: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-05-15 20:16:28.646278: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-05-15 20:16:28.655439: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./my_logs/run_20220515_201627/plugins/profile/2022_05_15_20_16_28\n",
      "\n",
      "2022-05-15 20:16:28.659001: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./my_logs/run_20220515_201627/plugins/profile/2022_05_15_20_16_28/DESKTOP-GC2VT9N.trace.json.gz\n",
      "2022-05-15 20:16:28.666398: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./my_logs/run_20220515_201627/plugins/profile/2022_05_15_20_16_28\n",
      "\n",
      "2022-05-15 20:16:28.666629: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./my_logs/run_20220515_201627/plugins/profile/2022_05_15_20_16_28/DESKTOP-GC2VT9N.memory_profile.json.gz\n",
      "2022-05-15 20:16:28.667218: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./my_logs/run_20220515_201627/plugins/profile/2022_05_15_20_16_28\n",
      "Dumped tool data for xplane.pb to ./my_logs/run_20220515_201627/plugins/profile/2022_05_15_20_16_28/DESKTOP-GC2VT9N.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./my_logs/run_20220515_201627/plugins/profile/2022_05_15_20_16_28/DESKTOP-GC2VT9N.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./my_logs/run_20220515_201627/plugins/profile/2022_05_15_20_16_28/DESKTOP-GC2VT9N.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./my_logs/run_20220515_201627/plugins/profile/2022_05_15_20_16_28/DESKTOP-GC2VT9N.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./my_logs/run_20220515_201627/plugins/profile/2022_05_15_20_16_28/DESKTOP-GC2VT9N.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4440 - accuracy: 0.8399 - val_loss: 0.3675 - val_accuracy: 0.8712\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3320 - accuracy: 0.8800 - val_loss: 0.3517 - val_accuracy: 0.8756\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2950 - accuracy: 0.8913 - val_loss: 0.3324 - val_accuracy: 0.8856\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2688 - accuracy: 0.9001 - val_loss: 0.3293 - val_accuracy: 0.8848\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2519 - accuracy: 0.9071 - val_loss: 0.3348 - val_accuracy: 0.8862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ebebdfaf0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "logs = os.path.join(os.curdir, \"my_logs\",\n",
    "                    \"run_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=10)\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set,\n",
    "          callbacks=[tensorboard_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc193aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ad8d0d8456316061\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ad8d0d8456316061\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "583a3cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84131840/84125825 [==============================] - 15s 0us/step\n",
      "84140032/84125825 [==============================] - 15s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/tatsuyafukui/.keras/datasets/aclImdb')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://ai.stanford.edu/~amaas/data/sentiment/\"\n",
    "FILENAME = \"aclImdb_v1.tar.gz\"\n",
    "filepath = keras.utils.get_file(\n",
    "    FILENAME, DOWNLOAD_ROOT + FILENAME, extract=True)\n",
    "path = Path(filepath).parent / \"aclImdb\"\n",
    "path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11ad022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb/\n",
      "    README\n",
      "    imdb.vocab\n",
      "    imdbEr.txt\n",
      "    test/\n",
      "        labeledBow.feat\n",
      "        urls_neg.txt\n",
      "        urls_pos.txt\n",
      "        neg/\n",
      "            0_2.txt\n",
      "            10000_4.txt\n",
      "            10001_1.txt\n",
      "            ...\n",
      "        pos/\n",
      "            0_10.txt\n",
      "            10000_7.txt\n",
      "            10001_9.txt\n",
      "            ...\n",
      "    train/\n",
      "        labeledBow.feat\n",
      "        unsupBow.feat\n",
      "        urls_neg.txt\n",
      "        ...\n",
      "        neg/\n",
      "            0_3.txt\n",
      "            10000_4.txt\n",
      "            10001_4.txt\n",
      "            ...\n",
      "        pos/\n",
      "            0_9.txt\n",
      "            10000_8.txt\n",
      "            10001_10.txt\n",
      "            ...\n",
      "        unsup/\n",
      "            0_0.txt\n",
      "            10000_0.txt\n",
      "            10001_0.txt\n",
      "            ...\n"
     ]
    }
   ],
   "source": [
    "for name, subdirs, files in os.walk(path):\n",
    "    indent = len(Path(name).parts) - len(path.parts)\n",
    "    print(\"    \" * indent + Path(name).parts[-1] + os.sep)\n",
    "    for index, filename in enumerate(sorted(files)):\n",
    "        if index == 3:\n",
    "            print(\"    \" * (indent + 1) + \"...\")\n",
    "            break\n",
    "        print(\"    \" * (indent + 1) + filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a15933ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500, 12500, 12500)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def review_paths(dirpath):\n",
    "    return [str(path) for path in dirpath.glob(\"*.txt\")]\n",
    "\n",
    "\n",
    "train_pos = review_paths(path / \"train\" / \"pos\")\n",
    "train_neg = review_paths(path / \"train\" / \"neg\")\n",
    "test_valid_pos = review_paths(path / \"test\" / \"pos\")\n",
    "test_valid_neg = review_paths(path / \"test\" / \"neg\")\n",
    "\n",
    "len(train_pos), len(train_neg), len(test_valid_pos), len(test_valid_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0dd0911",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(test_valid_pos)\n",
    "\n",
    "test_pos = test_valid_pos[:5000]\n",
    "test_neg = test_valid_neg[:5000]\n",
    "valid_pos = test_valid_pos[5000:]\n",
    "valid_neg = test_valid_neg[5000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60566e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_dataset(filepaths_positive, filepaths_negative):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for filepaths, label in ((filepaths_negative, 0), (filepaths_positive, 1)):\n",
    "        for filepath in filepaths:\n",
    "            with open(filepath) as review_file:\n",
    "                reviews.append(review_file.read())\n",
    "            labels.append(label)\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.constant(reviews), tf.constant(labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f78ee457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"Can I please say first of all, that I felt so strongly about this movie that I signed up to IMDb specifically to review it. And my review? This is easily the worst movie I have ever seen.<br /><br />The synopsis of the movie sounded interesting- Nazis, occult, time travel, etc., but the movies plot failed to properly bring all these elements together. Remember the episode of South Park that featured manatees writing Family Guy using 'idea balls'? Did these manatees also write Unholy? Its like the writer wanted to include all these different ideas, but had no idea how to link them all together, and then to make things make even less sense, included a Donnie Darko-esquire time travel theme to the ending, messing up the chronology.<br /><br />I could tell from early on that this was a bad movie. Special effects were too low budget for anything better than straight to DVD. The acting wasn't great, but in fairness I've seen worse. I will praise the Nazi paintings, they were creepy, but the evil Nazi butcher guy was just comic.<br /><br />I don't have a vendetta against this movie or anything, but to be honest, I'm not even into the horror genre. But this movie cannot be described as a thriller or a drama. If this story had been well told, this would have been a good movie. But it has been over hyped. Waaaaay over hyped.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n",
      "tf.Tensor(b'Note to Horror fans: The only horror here is when you realized you just wasted 95 minutes of your life on a movie that\\'s so worthless it\\'s insulting.<br /><br />I watched this because:<br /><br />The premise sounded slightly promising: It\\'s not. It\\'s just an excuse to use the same lame set pieces from other low-budget slasher films that weren\\'t good either. <br /><br />The promise of naked forest nymphs sounded nice even if the movie turned out to be awful: It\\'s not. It\\'s SO not. The amateur cinematography makes sure the \"fallen angels\" are about as sexy as the average homeless person.<br /><br />The name Tom Savini has a long history in the horror genre: He\\'s the king of low-budget special effects and lower-budget acting. Come to think of it, Savini should have been a reason not to watch this movie. It\\'s not that he\\'s bad, but he\\'s almost always in bad movies. His only good role was in From Dusk Till Dawn, and he\\'s been milking that at horror conventions ever since.<br /><br />But let\\'s focus on the positive: Forest of the Damned is a great example of how NOT to make a movie. <br /><br />Everything else is a negative. Obviously the writer is allergic to originality. The script is terrible. That\\'s all a given after the first 10 minutes. But the clueless pacing; the way the director treats \"plot\" and \"characterization\" as a nuisance he thinks no one cares about anyway; and the excruciatingly long and boring driving, walking, and nature sequences (no doubt added to increase the running time to make the film qualify for distribution) show a complete lack of aptitude for film and storytelling in general.<br /><br />This is another good example of the number-one way you can tell if a movie is going to be bad: If it\\'s written and directed by the same person, expect garbage.', shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n",
      "tf.Tensor(b'CQ is incredibly slow, and I\\'m a David Mamet fan. The movie follows around a young filmmaker who is making a very Barbarella-esque film. After that the movie started to lose me. Deep and profound? Not really. The movie \"Dragonfly\" being made in CQ has the problem of having no ending. This greatly parallels CQ, which also lacks an ending (in my opinion).<br /><br />I was lucky enough to catch this movie at the SxSW film festival. I had fairly high expectations having just watched Y Tu Mama Tambien and several other great movies. I was also looking forward to Jason Schwartzman\\'s performance. But it was not an easy film to get into. If you\\'re not into 60\\'s sci-fi or slow movies that go no where, skip it.<br /><br />CQ feels like a student film. If you want a recent sci-fi-esque indie film rent Donnie Darko, it won\\'t put you to sleep.', shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X, y in imdb_dataset(train_pos, train_neg).take(3):\n",
    "    print(X)\n",
    "    print(y)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6217902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.4 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).repeat(10): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "880e8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_dataset(filepaths_positive, filepaths_negative, n_read_threads=5):\n",
    "    dataset_neg = tf.data.TextLineDataset(filepaths_negative,\n",
    "                                          num_parallel_reads=n_read_threads)\n",
    "    dataset_neg = dataset_neg.map(lambda review: (review, 0))\n",
    "    dataset_pos = tf.data.TextLineDataset(filepaths_positive,\n",
    "                                          num_parallel_reads=n_read_threads)\n",
    "    dataset_pos = dataset_pos.map(lambda review: (review, 1))\n",
    "    return tf.data.Dataset.concatenate(dataset_pos, dataset_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "651a350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.7 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).cache().repeat(10): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb0f9dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_set = imdb_dataset(train_pos, train_neg).shuffle(\n",
    "    25000).batch(batch_size).prefetch(1)\n",
    "valid_set = imdb_dataset(valid_pos, valid_neg).batch(batch_size).prefetch(1)\n",
    "test_set = imdb_dataset(test_pos, test_neg).batch(batch_size).prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5358ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=string, numpy=\n",
       "array([[b'it', b's', b'a', b'great', b'great', b'movie', b'i', b'loved',\n",
       "        b'it', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
       "       [b'it', b'was', b'terrible', b'run', b'away', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>']], dtype=object)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(X_batch, n_words=50):\n",
    "    shape = tf.shape(X_batch) * tf.constant([1, 0]) + tf.constant([0, n_words])\n",
    "    Z = tf.strings.substr(X_batch, 0, 300)\n",
    "    Z = tf.strings.lower(Z)\n",
    "    Z = tf.strings.regex_replace(Z, b\"<br\\\\s*/?>\", b\" \")\n",
    "    Z = tf.strings.regex_replace(Z, b\"[^a-z]\", b\" \")\n",
    "    Z = tf.strings.split(Z)\n",
    "    return Z.to_tensor(shape=shape, default_value=b\"<pad>\")\n",
    "\n",
    "\n",
    "X_example = tf.constant(\n",
    "    [\"It's a great, great movie! I loved it.\", \"It was terrible, run away!!!\"])\n",
    "preprocess(X_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5d95008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<pad>',\n",
       " b'it',\n",
       " b'great',\n",
       " b's',\n",
       " b'a',\n",
       " b'movie',\n",
       " b'i',\n",
       " b'loved',\n",
       " b'was',\n",
       " b'terrible',\n",
       " b'run',\n",
       " b'away']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def get_vocabulary(data_sample, max_size=1000):\n",
    "    preprocessed_reviews = preprocess(data_sample).numpy()\n",
    "    counter = Counter()\n",
    "    for words in preprocessed_reviews:\n",
    "        for word in words:\n",
    "            if word != b\"<pad>\":\n",
    "                counter[word] += 1\n",
    "    return [b\"<pad>\"] + [word for word, count in counter.most_common(max_size)]\n",
    "\n",
    "\n",
    "get_vocabulary(X_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba0c73df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextVectorization(keras.layers.Layer):\n",
    "    def __init__(self, max_vocabulary_size=1000, n_oov_buckets=100, dtype=tf.string, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self.max_vocabulary_size = max_vocabulary_size\n",
    "        self.n_oov_buckets = n_oov_buckets\n",
    "\n",
    "    def adapt(self, data_sample):\n",
    "        self.vocab = get_vocabulary(data_sample, self.max_vocabulary_size)\n",
    "        words = tf.constant(self.vocab)\n",
    "        word_ids = tf.range(len(self.vocab), dtype=tf.int64)\n",
    "        vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "        self.table = tf.lookup.StaticVocabularyTable(\n",
    "            vocab_init, self.n_oov_buckets)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        preprocessed_inputs = preprocess(inputs)\n",
    "        return self.table.lookup(preprocessed_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a22fe1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=int64, numpy=\n",
       "array([[ 1,  3,  4,  2,  2,  5,  6,  7,  1,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 1,  8,  9, 10, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization = TextVectorization()\n",
    "\n",
    "text_vectorization.adapt(X_example)\n",
    "text_vectorization(X_example)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88f8b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocabulary_size = 1000\n",
    "n_oov_buckets = 100\n",
    "\n",
    "sample_review_batches = train_set.map(lambda review, _: review)\n",
    "sample_reviews = np.concatenate(list(sample_review_batches.as_numpy_iterator()),\n",
    "                                axis=0)\n",
    "\n",
    "text_vectorization = TextVectorization(max_vocabulary_size, n_oov_buckets,\n",
    "                                       input_shape=[])\n",
    "text_vectorization.adapt(sample_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82e8f725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=int64, numpy=\n",
       "array([[  9,  14,   2,  64,  64,  12,   5, 257,   9,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  9,  13, 269, 530, 334,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization(X_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0617ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<pad>', b'the', b'a', b'of', b'and', b'i', b'to', b'is', b'this', b'it']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization.vocab[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "426f7957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[2., 2., 0., 1.],\n",
       "       [3., 0., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_example = tf.constant([[1, 3, 1, 0, 0], [2, 2, 0, 0, 0]])\n",
    "tf.reduce_sum(tf.one_hot(simple_example, 4), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf285a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWords(keras.layers.Layer):\n",
    "    def __init__(self, n_tokens, dtype=tf.int32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self.n_tokens = n_tokens\n",
    "\n",
    "    def call(self, inputs):\n",
    "        one_hot = tf.one_hot(inputs, self.n_tokens)\n",
    "        return tf.reduce_sum(one_hot, axis=1)[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "daf03f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[2., 0., 1.],\n",
       "       [0., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = BagOfWords(n_tokens=4)\n",
    "bag_of_words(simple_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15350d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = max_vocabulary_size + n_oov_buckets + 1  # add 1 for <pad>\n",
    "bag_of_words = BagOfWords(n_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95cc20d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 12s 11ms/step - loss: 0.5435 - accuracy: 0.7176 - val_loss: 0.5098 - val_accuracy: 0.7404\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 13s 13ms/step - loss: 0.4731 - accuracy: 0.7682 - val_loss: 0.5046 - val_accuracy: 0.7468\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 13s 13ms/step - loss: 0.4239 - accuracy: 0.8040 - val_loss: 0.5086 - val_accuracy: 0.7462\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 13s 13ms/step - loss: 0.3543 - accuracy: 0.8506 - val_loss: 0.5402 - val_accuracy: 0.7371\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 13s 13ms/step - loss: 0.2728 - accuracy: 0.8980 - val_loss: 0.5922 - val_accuracy: 0.7225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f6a9994f0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    text_vectorization,\n",
    "    bag_of_words,\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30ba8fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.535534 , 4.9497476, 2.1213205],\n",
       "       [6.       , 0.       , 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_mean_embedding(inputs):\n",
    "    not_pad = tf.math.count_nonzero(inputs, axis=-1)\n",
    "    n_words = tf.math.count_nonzero(not_pad, axis=-1, keepdims=True)\n",
    "    sqrt_n_words = tf.math.sqrt(tf.cast(n_words, tf.float32))\n",
    "    return tf.reduce_sum(inputs, axis=1) / sqrt_n_words\n",
    "\n",
    "\n",
    "another_example = tf.constant([[[1., 2., 3.], [4., 5., 0.], [0., 0., 0.]],\n",
    "                               [[6., 0., 0.], [0., 0., 0.], [0., 0., 0.]]])\n",
    "compute_mean_embedding(another_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6a36ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[3.535534 , 4.9497476, 2.1213202]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(another_example[0:1, :2], axis=1) * tf.sqrt(2.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69c803cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[6., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(another_example[1:2, :1], axis=1) * tf.sqrt(1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38569c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 20\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    text_vectorization,\n",
    "    keras.layers.Embedding(input_dim=n_tokens,\n",
    "                           output_dim=embedding_size,\n",
    "                           mask_zero=True),  # <pad> tokens => zero vectors\n",
    "    keras.layers.Lambda(compute_mean_embedding),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "323e3545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 8s 6ms/step - loss: 0.5547 - accuracy: 0.7075 - val_loss: 0.5137 - val_accuracy: 0.7426\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 8s 8ms/step - loss: 0.4968 - accuracy: 0.7536 - val_loss: 0.5127 - val_accuracy: 0.7404\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 10s 9ms/step - loss: 0.4873 - accuracy: 0.7599 - val_loss: 0.5070 - val_accuracy: 0.7422\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 10s 10ms/step - loss: 0.4800 - accuracy: 0.7632 - val_loss: 0.5025 - val_accuracy: 0.7422\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 12s 11ms/step - loss: 0.4731 - accuracy: 0.7649 - val_loss: 0.5040 - val_accuracy: 0.7413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f6b26bfa0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63773bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 22:29:22.788194: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /home/tatsuyafukui/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c970927d97421e89bbc2e7f8998826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068ad00be87e4a2e8ed1f90b41b5eba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc4c6054ada4d7ab1741bad50cd2094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf72ec7e74bf44b8aa7024ec7a121a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d7ee5253e6488fa620b5ffba29b432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/tatsuyafukui/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteEEOZ91/imdb_reviews-t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bc3c5d90e94aba97b0fc13bf8d019e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f560353603941f990e92846ae80655c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/tatsuyafukui/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteEEOZ91/imdb_reviews-t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb17da2128a84aca98a54ec54a74c5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6d90ba4ab143209e22071d275fe535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/tatsuyafukui/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteEEOZ91/imdb_reviews-u…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to /home/tatsuyafukui/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets = tfds.load(name=\"imdb_reviews\")\n",
    "train_set, test_set = datasets[\"train\"], datasets[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33158c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 22:30:09.824931: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for example in train_set.take(1):\n",
    "    print(example[\"text\"])\n",
    "    print(example[\"label\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
